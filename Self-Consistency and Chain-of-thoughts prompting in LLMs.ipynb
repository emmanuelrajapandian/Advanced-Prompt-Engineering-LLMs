{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fbaa615f3e2c4817a9e77475cdd45754": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c50e94d85d9941f0b01cf64ff52b9aaf",
              "IPY_MODEL_44f8815b8101453f89536cfa974103f6",
              "IPY_MODEL_4d65f1a962be496385c027b8fd5f66ec"
            ],
            "layout": "IPY_MODEL_e7b52e77353348d193180c3634195d4d"
          }
        },
        "c50e94d85d9941f0b01cf64ff52b9aaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb40e90c3b7e4c12a33273319dfeecc8",
            "placeholder": "​",
            "style": "IPY_MODEL_3a67de8ca0ec4231bc6e6c0f8af1b666",
            "value": ""
          }
        },
        "44f8815b8101453f89536cfa974103f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_676f5ad2fe794c1296c047d88294f3e6",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_52e9c9a69d2f4da7aaeefc8aa80c625b",
            "value": 0
          }
        },
        "4d65f1a962be496385c027b8fd5f66ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96b128bfe3724d2981e129e2c45c3f91",
            "placeholder": "​",
            "style": "IPY_MODEL_045689a293aa4556a1cdba19e94a32c1",
            "value": " 0/0 [00:00&lt;?, ?it/s]"
          }
        },
        "e7b52e77353348d193180c3634195d4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb40e90c3b7e4c12a33273319dfeecc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a67de8ca0ec4231bc6e6c0f8af1b666": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "676f5ad2fe794c1296c047d88294f3e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "52e9c9a69d2f4da7aaeefc8aa80c625b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "96b128bfe3724d2981e129e2c45c3f91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "045689a293aa4556a1cdba19e94a32c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Self-Consistency and Chain-of-thoughts prompting in LLMs\n",
        "\n",
        "In this notebook, I'll employ the [Mixtral8x7B-Instruct](https://huggingface.co/mistralai/Mixtral-8x7B-v0.1) LLM model to explore and apply chain-of-thought and self-consistency prompting techniques. This involves practically learning these methods by applying on various examples.\n",
        "\n",
        "This  LLM is capable enough to run on google colab thanks to **Denis Mazur** and **Artyom Eliseev** who have made this possible by quantizing the original model in mixed precision and implementing a MoE-specific offloading strategy. `[Quantization, build_model, Expert MoE files were forked from their github repo]`.\n",
        "\n",
        "Read their [tech report](https://arxiv.org/abs/2312.17238). I will try to summarize my learnings from their report in the following days in this notebook.\n",
        "\n",
        "\n",
        "##### *Edited: 01-09-2024.*"
      ],
      "metadata": {
        "id": "OW1moHJ1TdhO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install and import libraries"
      ],
      "metadata": {
        "id": "Y8MhvkC7TKEL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML, display, Markdown\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)\n",
        "\n",
        "HTML('''<script>\n",
        "code_show_err=false;\n",
        "function code_toggle_err() {\n",
        " if (code_show_err){\n",
        " $('div.output_stderr').hide();\n",
        " } else {\n",
        " $('div.output_stderr').show();\n",
        " }\n",
        " code_show_err = !code_show_err\n",
        "}\n",
        "$( document ).ready(code_toggle_err);\n",
        "</script>''')"
      ],
      "metadata": {
        "id": "Cm6njCbRHGja",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "512c8c87-769e-42d7-c58e-324f7341b75d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<script>\n",
              "code_show_err=false;\n",
              "function code_toggle_err() {\n",
              " if (code_show_err){\n",
              " $('div.output_stderr').hide();\n",
              " } else {\n",
              " $('div.output_stderr').show();\n",
              " }\n",
              " code_show_err = !code_show_err\n",
              "}\n",
              "$( document ).ready(code_toggle_err);\n",
              "</script>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "f7qY7ebqX7T7"
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# fix triton in colab\n",
        "!export LC_ALL=\"en_US.UTF-8\"\n",
        "!export LD_LIBRARY_PATH=\"/usr/lib64-nvidia\"\n",
        "!export LIBRARY_PATH=\"/usr/local/cuda/lib64/stubs\"\n",
        "!ldconfig /usr/lib64-nvidia\n",
        "\n",
        "!git clone https://github.com/emmanuelrajapandian/Advanced-Prompt-Engineering-LLMs.git --quiet\n",
        "!cd Advanced-Prompt-Engineering-LLMs && pip install -q -r requirements.txt\n",
        "!huggingface-cli download lavawolfiee/Mixtral-8x7B-Instruct-v0.1-offloading-demo --quiet --local-dir Mixtral-8x7B-Instruct-v0.1-offloading-demo\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "sys.path.append(\"Advanced-Prompt-Engineering-LLMs\")\n",
        "import torch\n",
        "from torch.nn import functional as F\n",
        "from hqq.core.quantize import BaseQuantizeConfig\n",
        "from langchain.prompts import PromptTemplate\n",
        "from huggingface_hub import snapshot_download\n",
        "from IPython.display import clear_output\n",
        "from tqdm.auto import trange\n",
        "from transformers import AutoConfig, AutoTokenizer\n",
        "from transformers.utils import logging as hf_logging\n",
        "\n",
        "from source.build_model import OffloadConfig, QuantConfig, build_model"
      ],
      "metadata": {
        "id": "GgpjnV7fV49W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "fbaa615f3e2c4817a9e77475cdd45754",
            "c50e94d85d9941f0b01cf64ff52b9aaf",
            "44f8815b8101453f89536cfa974103f6",
            "4d65f1a962be496385c027b8fd5f66ec",
            "e7b52e77353348d193180c3634195d4d",
            "eb40e90c3b7e4c12a33273319dfeecc8",
            "3a67de8ca0ec4231bc6e6c0f8af1b666",
            "676f5ad2fe794c1296c047d88294f3e6",
            "52e9c9a69d2f4da7aaeefc8aa80c625b",
            "96b128bfe3724d2981e129e2c45c3f91",
            "045689a293aa4556a1cdba19e94a32c1"
          ]
        },
        "outputId": "acf4b4c9-d2ed-4e2e-8f2d-59ac4696c19a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hqq_aten package not installed. HQQBackend.ATEN backend will not work unless you install the hqq_aten lib in hqq/kernels.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fbaa615f3e2c4817a9e77475cdd45754"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize model"
      ],
      "metadata": {
        "id": "OkSYibHcTQsH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
        "quantized_model_name = \"lavawolfiee/Mixtral-8x7B-Instruct-v0.1-offloading-demo\"\n",
        "state_path = \"Mixtral-8x7B-Instruct-v0.1-offloading-demo\"\n",
        "\n",
        "config = AutoConfig.from_pretrained(quantized_model_name)\n",
        "device = torch.device(\"cuda:0\")\n",
        "\n",
        "offload_per_layer = 4\n",
        "num_experts = config.num_local_experts\n",
        "\n",
        "offload_config = OffloadConfig(\n",
        "    main_size=config.num_hidden_layers * (num_experts - offload_per_layer),\n",
        "    offload_size=config.num_hidden_layers * offload_per_layer,\n",
        "    buffer_size=4,\n",
        "    offload_per_layer=offload_per_layer,\n",
        ")\n",
        "\n",
        "\n",
        "attn_config = BaseQuantizeConfig(\n",
        "    nbits=4,\n",
        "    group_size=64,\n",
        "    quant_zero=True,\n",
        "    quant_scale=True,\n",
        ")\n",
        "\n",
        "attn_config[\"scale_quant_params\"][\"group_size\"] = 256\n",
        "\n",
        "ffn_config = BaseQuantizeConfig(\n",
        "    nbits=2,\n",
        "    group_size=16,\n",
        "    quant_zero=True,\n",
        "    quant_scale=True,\n",
        ")\n",
        "quant_config = QuantConfig(ffn_config=ffn_config, attn_config=attn_config)\n",
        "\n",
        "\n",
        "# Building the Model after specifying the params in the instantiated Classes\n",
        "# OffloadConfig(), BaseQuantizeConfig().\n",
        "model = build_model(\n",
        "    device=device,\n",
        "    quant_config=quant_config,\n",
        "    offload_config=offload_config,\n",
        "    state_path=state_path,\n",
        ")\n",
        "\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "_mIpePTMFyRY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run the model"
      ],
      "metadata": {
        "id": "Z4hBFYtPTUzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TextStreamer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)\n",
        "past_key_values = None\n",
        "sequence = None\n",
        "\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "Zf4GkspecSm8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_outputs(prompt:str, temperature:float, max_tokens:int=128, do_sample:bool=True, stop_sequences:list=[], n:int=1) -> list:\n",
        "    \"\"\"\n",
        "    Function to run inference with Mixtral model\n",
        "    \"\"\"\n",
        "    user_entry = dict(role=\"user\", content=prompt)\n",
        "    input_ids = tokenizer.apply_chat_template([user_entry], return_tensors=\"pt\").to(device)\n",
        "\n",
        "    outputs = []\n",
        "    for i in range(n):\n",
        "        outputs.append(model.generate(input_ids=input_ids,\n",
        "                                      streamer=streamer,\n",
        "                                      do_sample=do_sample,\n",
        "                                      temperature=temperature,\n",
        "                                      top_p=0.9,\n",
        "                                      max_new_tokens=max_tokens,\n",
        "                                      pad_token_id=tokenizer.eos_token_id,\n",
        "                                      return_dict_in_generate=True,\n",
        "                                      output_hidden_states=False,))\n",
        "    return outputs"
      ],
      "metadata": {
        "id": "HIKlmO4ulryT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "e2d3988c-9f18-43db-8fa9-b20dec5d44d0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TEMP = 0.9\n",
        "output = generate_outputs(\"What is the pet of Phineas and Ferb called and what does it do?\", TEMP, max_tokens=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "4otDPaSCGJpS",
        "outputId": "24c74fa9-51d6-4686-e720-1f70a98d0945"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Phineas Flynn and Ferb Fletcher's pet in the animated show \"Phineas and Ferb\" is a platypus named Perry. However, Perry is not just an ordinary pet, as he leads a double life: when the boys are not using him for a backyard adventure, Perry removes his pet collar and becomes Agent P, a secret agent fighting evil.\n",
            "\n",
            "Perry, the pet platypus, does not have any supernatural powers, but he is very intelligent, agile, and skilled in martial arts. He uses gadgets and tools created by Phineas\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TEMP = 0.9\n",
        "output = generate_outputs(\"What are the commands in Mac to push, pull, merge repos in github from the local terminal?\",\n",
        "                          TEMP, max_tokens=256)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "uLsrRh6KHgkf",
        "outputId": "a43c199f-af88-4b7d-968a-e45936181c24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To perform Git operations on a Mac, you will first need to navigate to the local directory that contains the Git repository using the `cd` command. Once you are in the directory that contains the Git repository, you can use the following commands:\n",
            "\n",
            "* To pull changes from the remote repository, use the command:\n",
            "```\n",
            "git pull origin <branch-name>\n",
            "```\n",
            "* To push your local changes to the remote repository, use the command:\n",
            "```\n",
            "git push origin <branch-name>\n",
            "```\n",
            "* To merge changes from one branch onto another, use the command:\n",
            "```\n",
            "git merge branch-name\n",
            "```\n",
            "Here, `origin` refers to the remote repository where the Git operations are being performed, and `<branch-name>` is the name of the branch that you want to merge.\n",
            "\n",
            "You may also need to use the `git add` and `git commit` commands to add and commit changes to your local repository before pushing them to the remote repository.\n",
            "\n",
            "To learn more about these and other Git commands, you can refer to the official Git documentation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Greedy Decoding"
      ],
      "metadata": {
        "id": "r0nAGxKqs8pb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"In less than 40 words, finish the sentence 'I want to go to the market to\"\n",
        "TEMP = 0.0\n",
        "\n",
        "while True:\n",
        "  output = generate_outputs(prompt, TEMP, do_sample=False, max_tokens=64, n=3)\n",
        "  print(\"\\n\")\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "877UuyIvfGNm",
        "outputId": "8b1d378b-c589-4702-9164-0e4b638bc31a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I want to go to the market to buy fresh fruits and vegetables, affordable spices, and meet friendly locals to learn about their culture and cuisine.\n",
            "I want to go to the market to buy fresh fruits and vegetables, affordable spices, and meet friendly locals to learn about their culture and cuisine.\n",
            "I want to go to the market to buy fresh fruits and vegetables, affordable spices, and meet friendly locals to learn about their culture and cuisine.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stochastic Decoding, controlled by temperature."
      ],
      "metadata": {
        "id": "QXysyTFHtAyY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"In less than 40 words, finish the sentence 'I want to go to the market to\"\n",
        "TEMP = 1.0\n",
        "\n",
        "while True:\n",
        "  output = generate_outputs(prompt, TEMP, max_tokens=64, n=3)\n",
        "  print(\"\\n\")\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "lwImKwDXfGKj",
        "outputId": "398cc380-d276-4c0d-d074-20ee9c1a097d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I want to go to the market to buy fresh fruits and vegetables, delicious baked goods, and maybe even find some unique gifts from local vendors. It's a great way to support the community while getting some fresh air and sunshine.\n",
            "I want to go to the market to buy fresh fruits and vegetables, delicious baked goods, and maybe even find some new recipes to try. It's a chance to discover new foods and support local farmers.\n",
            "I want to go to the market to buy fresh fruits and vegetables, delicious baked goods, and high-quality meat from local farmers. I also enjoy the hustle and bustle of the market and discovering new products and foods.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "few_shot_analysis_examples = \"\"\"\n",
        "The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1.\n",
        "A: Adding all the odd numbers (9, 15, 1) gives 25. The answer is False.\n",
        "The odd numbers in this group add up to an even number: 17, 10, 19, 4, 8, 12, 24.\n",
        "A: Adding all the odd numbers (17, 19) gives 36. The answer is True.\n",
        "The odd numbers in this group add up to an even number: 16, 11, 14, 4, 8, 7, 24.\n",
        "A: Adding all the odd numbers (11, 7) gives 18. The answer is True.\n",
        "The odd numbers in this group add up to an even number: 17, 9, 10, 12, 13, 4, 2.\n",
        "A: Adding all the odd numbers (17, 9, 13) gives 39. The answer is False.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "pX4qy3hofF_E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "13bd30b6-89f6-4943-b6cd-b96c798c6503"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"\"\"\n",
        "The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 1.\n",
        "A:\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "ztgBEqDLNeP0",
        "outputId": "d5f43ff3-1cfc-4759-f3ef-e5eb9b43e3a4"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cot_template = \"\"\"\n",
        "{few_shot_examples}\n",
        "\n",
        "{question}\n",
        "Follow the examples as it is and answer the question in the same format as the examples. Do not frame extra sentences.\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate.from_template(cot_template).format(\n",
        "    few_shot_examples=few_shot_analysis_examples,\n",
        "    question=question\n",
        ")\n",
        "\n",
        "TEMP = 0.1\n",
        "output = generate_outputs(prompt, TEMP, max_tokens=256, stop_sequences=[\".\", \"\\n\", \"\"])"
      ],
      "metadata": {
        "id": "UVMYL9i60q9r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8aab23bc-05d1-4305-efc3-ba3524ab0ecf"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The odd numbers in this group are 15, 5, 13, 1. Adding them up gives 34, which is an even number. So the answer is True.\n"
          ]
        }
      ]
    }
  ]
}